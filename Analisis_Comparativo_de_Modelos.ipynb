{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b5383eb",
   "metadata": {},
   "source": [
    "# Análisis Comparativo de Modelos de Machine Learning para la Predicción de Diabetes\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "Este documento presenta un análisis exhaustivo de los diferentes modelos de aprendizaje automático entrenados para la predicción de diabetes. Se evaluaron diversos algoritmos para identificar el más adecuado en términos de precisión, sensibilidad y capacidad de discriminación.\n",
    "\n",
    "## 2. Resumen de Modelos Evaluados\n",
    "\n",
    "Se entrenaron y evaluaron siete modelos diferentes:\n",
    "\n",
    "| Modelo                       | Accuracy | AUC       | Precisión | Recall   | F1-Score | Características                                    |\n",
    "| ---------------------------- | -------- | --------- | --------- | -------- | -------- | ------------------------------------------------- |\n",
    "| KNN (k=19)                   | 0.7346   | 0.806     | 0.72      | 0.77     | 0.73     | Buen equilibrio, fácil interpretación             |\n",
    "| Regresión Logística          | 0.7532   | 0.829     | 0.75      | 0.75     | 0.75     | Alta estabilidad y buen rendimiento               |\n",
    "| Árbol de Decisión (base)     | 0.6571   | 0.657     | 0.66      | 0.65     | 0.66     | Alta interpretabilidad pero bajo rendimiento      |\n",
    "| Árbol de Decisión (opt.)     | 0.7381   | 0.801     | 0.71      | 0.79     | 0.73     | Mejor después de optimización de hiperparámetros  |\n",
    "| Random Forest (base)         | 0.7376   | 0.811     | 0.74      | 0.74     | 0.74     | Robusto y resistente al sobreajuste              |\n",
    "| Random Forest (opt.)         | 0.7506   | 0.825     | 0.75      | 0.76     | 0.75     | Mejora después de ajuste de hiperparámetros       |\n",
    "| **XGBoost (base)**           | 0.7555   | 0.8302    | 0.7370    | 0.7971   | 0.7659   | Mejor rendimiento general                         |\n",
    "| **XGBoost (opt. umbral 0.40)**| 0.7436   | 0.8275    | 0.6945    | **0.8728** | **0.7735** | Maximiza recall manteniendo buen F1-score     |\n",
    "\n",
    "## 3. Análisis del Modelo XGBoost\n",
    "\n",
    "### 3.1 Configuración Óptima\n",
    "\n",
    "El modelo XGBoost optimizado presenta los siguientes hiperparámetros:\n",
    "- **n_estimators**: 100 (número de árboles)\n",
    "- **learning_rate**: 0.2 (tasa de aprendizaje)\n",
    "- **max_depth**: 3 (profundidad máxima del árbol)\n",
    "- **umbral de probabilidad**: 0.40 (ajustado para maximizar F1-score)\n",
    "\n",
    "### 3.2 Características Más Relevantes\n",
    "\n",
    "El análisis de importancia de características identificó las variables más influyentes:\n",
    "\n",
    "1. **HighBP** (40.79%): Presión arterial alta\n",
    "2. **GenHlth_2** (6.01%): Salud general \n",
    "3. **DiffWalk** (5.08%): Dificultad para caminar\n",
    "4. **BMI**: Índice de masa corporal\n",
    "5. **Age_13**: Grupo de edad avanzada\n",
    "\n",
    "Esto sugiere que los factores cardiovasculares y metabólicos son los principales indicadores predictivos de diabetes, lo que coincide con la literatura médica sobre factores de riesgo.\n",
    "\n",
    "### 3.3 Impacto del Ajuste de Umbral\n",
    "\n",
    "La modificación del umbral de decisión de 0.50 a 0.40 produjo:\n",
    "\n",
    "- **Incremento significativo en Recall**: De 0.7971 a 0.8728 (+7.57%)\n",
    "- **Reducción en Precisión**: De 0.7370 a 0.6945 (-4.25%)\n",
    "- **Mejora en F1-Score**: De 0.7659 a 0.7735 (+0.76%)\n",
    "\n",
    "Esta configuración prioriza la identificación de casos positivos (personas con diabetes), minimizando los falsos negativos, lo cual es crítico en aplicaciones médicas donde pasar por alto un caso puede tener consecuencias graves.\n",
    "\n",
    "### 3.4 Matriz de Confusión del Modelo Final\n",
    "\n",
    "Con el umbral optimizado a 0.40:\n",
    "\n",
    "| | **Predicción: No Diabetes** | **Predicción: Diabetes** |\n",
    "|----------------------|--------------------------|------------------------|\n",
    "| **Real: No Diabetes** | 3891 (VN) | 2451 (FP) |\n",
    "| **Real: Diabetes** | 812 (FN) | 5571 (VP) |\n",
    "\n",
    "- **Verdaderos Positivos (VP)**: 5571 casos de diabetes correctamente identificados\n",
    "- **Falsos Negativos (FN)**: 812 casos de diabetes no detectados\n",
    "- **Falsos Positivos (FP)**: 2451 personas incorrectamente clasificadas con diabetes\n",
    "- **Verdaderos Negativos (VN)**: 3891 personas sin diabetes correctamente clasificadas\n",
    "\n",
    "## 4. Curva ROC y Capacidad Discriminativa\n",
    "\n",
    "El modelo XGBoost optimizado logra un AUC de 0.8275, indicando una excelente capacidad para discriminar entre personas con y sin diabetes. La curva ROC muestra una separación significativa de la diagonal (clasificación aleatoria), confirmando la robustez del modelo.\n",
    "\n",
    "## 5. Proceso de Selección de Características\n",
    "\n",
    "Se aplicó un umbral de importancia de 0.01 para seleccionar características relevantes, lo que permitió:\n",
    "\n",
    "1. Reducir la dimensionalidad del conjunto de datos\n",
    "2. Mantener un rendimiento similar con menos variables\n",
    "3. Disminuir el riesgo de sobreajuste\n",
    "4. Mejorar la interpretabilidad del modelo\n",
    "\n",
    "La selección de características mostró que se puede mantener la capacidad predictiva (AUC 0.8267 vs 0.8302 original) utilizando menos variables, lo que optimiza la eficiencia computacional.\n",
    "\n",
    "## 6. Comparación con Otros Algoritmos\n",
    "\n",
    "En comparación con los demás modelos:\n",
    "\n",
    "- **XGBoost vs. Regresión Logística**: XGBoost muestra un recall significativamente superior (0.87 vs 0.79) y ligeramente mejor F1-score.\n",
    "- **XGBoost vs. Random Forest**: Ambos tienen AUC similar, pero XGBoost logra mejor recall y F1-score.\n",
    "- **XGBoost vs. KNN**: XGBoost supera a KNN en todas las métricas, especialmente en recall.\n",
    "- **XGBoost vs. Árbol de Decisión**: Mejora sustancial en todas las métricas, especialmente en AUC (+0.17).\n",
    "\n",
    "## 7. Conclusiones y Recomendaciones\n",
    "\n",
    "### 7.1 Modelo Recomendado\n",
    "\n",
    "**XGBoost con umbral ajustado a 0.40** es el modelo óptimo para implementar en la aplicación web debido a:\n",
    "\n",
    "1. **Máximo recall (0.8728)**: Identifica el 87.28% de los casos de diabetes, minimizando el riesgo de pasar por alto casos positivos.\n",
    "2. **Mejor F1-Score global (0.7735)**: Logra el mejor balance entre precisión y recall.\n",
    "3. **Alto AUC (0.8275)**: Excelente capacidad discriminativa.\n",
    "4. **Robustez**: El algoritmo es menos propenso al sobreajuste que un árbol de decisión simple.\n",
    "\n",
    "### 7.2 Consideraciones para la Implementación Web\n",
    "\n",
    "1. **Preprocesamiento**: Incorporar las transformaciones aplicadas durante el entrenamiento:\n",
    "   - Manejo de valores atípicos en BMI\n",
    "   - Escalado de variables numéricas\n",
    "   - Codificación adecuada de variables categóricas\n",
    "\n",
    "2. **Umbral de clasificación**: Configurar el umbral de probabilidad en 0.40 para favorecer la detección de casos positivos.\n",
    "\n",
    "3. **Interpretabilidad**: Incluir la explicación de las variables más importantes en la interfaz de usuario para contextualizar los resultados.\n",
    "\n",
    "4. **Presentación de resultados**: Mostrar tanto la predicción final como la probabilidad estimada para una evaluación más completa.\n",
    "\n",
    "5. **Persistencia del modelo**: Utilizar el archivo modelo_xgboost_optimizado.pkl previamente guardado para implementar las predicciones.\n",
    "\n",
    "### 7.3 Trabajo Futuro\n",
    "\n",
    "1. **Validación externa**: Evaluar el modelo con datos de otras poblaciones para confirmar su generalización.\n",
    "\n",
    "2. **Implementación de explicabilidad**: Incorporar técnicas como SHAP para explicar predicciones individuales.\n",
    "\n",
    "3. **Monitorización continua**: Implementar un sistema de seguimiento del rendimiento del modelo en producción.\n",
    "\n",
    "4. **Reentrenamiento periódico**: Establecer un proceso para actualizar el modelo con nuevos datos.\n",
    "\n",
    "5. **Adaptación de umbral**: Permitir ajustes del umbral según necesidades específicas (mayor precisión o mayor recall).\n",
    "\n",
    "Este análisis exhaustivo demuestra que el modelo XGBoost con umbral optimizado ofrece la mejor combinación de rendimiento e interpretabilidad para la implementación en una aplicación web de predicción de diabetes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
